{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZgGNXZEfywz"
   },
   "source": [
    "#Task 1: Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deLPHwbIX3-r"
   },
   "outputs": [],
   "source": [
    "# Download gutenberg dataset\n",
    "# This is the dataset on which all your models will be trained\n",
    "# https://drive.google.com/file/d/0B2Mzhc7popBga2RkcWZNcjlRTGM/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below task uses a regex to break a the grammer in words but the terminals do not get handled here. I have made a handler loop for breaking down sentences and add <EOS> ie End of Sentence in the end of every sentence as it woould be required in n-gram model generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08q0ospof2z9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------TOKENS-----------------------------------------------------\n",
      "['i', 'am', 'a', 'i', 'am', 'a', 'mr.', 'john', 'johnson', 'jr.', 'was', 'born', 'in', 'the', 'u.s.a', 'but', 'earned', 'his', 'ph.d.', 'in', 'israel', 'before', 'joining', 'nike', 'inc.', 'as', 'an', 'engineer', '<EOS>', 'he', 'also', 'worked', 'at', 'craigslist.org', 'as', 'a', 'business', 'analyst', '<EOS>', 'mr.', 'smith', 'bought', 'cheapsite.com', 'for', '1.5', 'million', 'dollars', '<EOS>', 'i.e.', 'he', 'paid', 'a', 'lot', 'for', 'it', '<EOS>', 'did', 'he', 'mind', '<EOS>', 'adam', 'jones', 'jr.', 'thinks', 'he', 'didnt', '<EOS>', 'in', 'any', 'case', '<EOS>', 'this', \"isn't\", 'true', '<EOS>', 'well', '<EOS>', 'with', 'a', 'probability', 'of', '0.9', 'it', \"isn't\", \"don's\", 'in', 'israel', 'ok', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "import sys, re\n",
    "import plotly as py\n",
    "py.tools.set_credentials_file(username='sunchitsharma9',api_key='1e8V1NqDZtCw9ci0ZLil')\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def is_number(s): # Helper Functions\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    text = text.lower(); # Case Folding\n",
    "    \n",
    "    split_text = re.split('''a-z|\n",
    "                          ,|\n",
    "                          \\n| |\n",
    "                          \\r|\n",
    "                          \\*|\n",
    "                          --|\n",
    "                          !|\n",
    "                          \\?|\n",
    "                          ; |\n",
    "                          \\\"|\n",
    "                          _|\n",
    "                          \\]|\n",
    "                          \\[''',text)\n",
    "    \n",
    "    # The issue is that we have not handled \".\" and Dr. and such types are not handled.\n",
    "    \n",
    "    Dot_Handler = [\"ie.\",\"i.e.\",\"inc.\",\"i.o.u.\",\"m.d.\",\"n.b.\",\"p.o.\",\"u.k.\",\"u.s.\",\"u.s.a.\",\"p.s.\",\".c\",\"mr.\",\"mrs.\",\"ms.\",\".com\",\"dr.\",\".sh\",\".java\",\"st.\",\"jr.\",\"ph.d.\"]\n",
    "    \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    \n",
    "    # Web_Extentions = [\".com\",\".in\",\".org\",\".edu\",\".net\",\".gov\",\".info\",\".biz\"] Automatically Handled\n",
    "    \n",
    "    counter = -1;\n",
    "    \n",
    "    for i in split_text:\n",
    "        counter+=1\n",
    "        if i[-1] in punctuations:\n",
    "            if i not in Dot_Handler:\n",
    "                temp = re.sub(r'[^\\w\\s]','',i)\n",
    "                split_text[counter]=temp\n",
    "                split_text.insert(counter, \"<EOS>\")\n",
    "                \n",
    "    counter = -1;\n",
    "    \n",
    "    for i in split_text :\n",
    "        if counter<len(split_text)-1:\n",
    "            counter+=1\n",
    "            if split_text[counter] == \"<EOS>\":\n",
    "                t1=split_text[counter]\n",
    "                split_text[counter]=split_text[counter+1]\n",
    "                split_text[counter+1]=t1\n",
    "                counter+=1\n",
    "                \n",
    "    return split_text\n",
    "    \n",
    "\n",
    "text = \"i am a i am a Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst. Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "tokens=tokenize(text)\n",
    "print \"-----------------------------------------------------TOKENS-----------------------------------------------------\"\n",
    "print tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gwBEe5bgAbn"
   },
   "source": [
    "#Language Model and Smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model, Plotting, Smoothing, Word Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Th9ogrogKTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Top ten N-Grams------\n",
      "('i', 'am', 'a')\t\t:\t2\n",
      "('am', 'a', 'i')\t\t:\t2\n",
      "('a', 'i', 'am')\t\t:\t2\n",
      "('worked', 'at', 'craigslist.org')\t\t:\t1\n",
      "('with', 'a', 'probability')\t\t:\t1\n",
      "('was', 'born', 'in')\t\t:\t1\n",
      "('u.s.a', 'but', 'earned')\t\t:\t1\n",
      "('this', \"isn't\", 'true')\t\t:\t1\n",
      "('thinks', 'he', 'didnt')\t\t:\t1\n",
      "------Bottom ten N-Grams------\n",
      "('0.9', 'it', \"isn't\")     :     1\n",
      "('1.5', 'million', 'dollars')     :     1\n",
      "('a', 'business', 'analyst')     :     1\n",
      "('a', 'lot', 'for')     :     1\n",
      "('a', 'probability', 'of')     :     1\n",
      "('adam', 'jones', 'jr.')     :     1\n",
      "('also', 'worked', 'at')     :     1\n",
      "('am', 'the', 'mr.')     :     1\n",
      "('as', 'a', 'business')     :     1\n",
      "\n",
      "LAPLACE : \n",
      "0.0105263157895\n",
      "\n",
      "GOOD TURING : \n",
      "0.2375\n",
      "\n",
      "BACKOFF : \n",
      "2.76012355953\n",
      "\n",
      "NEXT POSSIBLE WORDS WITH FREQUENCIES\n",
      "a\t:\t2\n",
      "the\t:\t1\n",
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~sunchitsharma9/0 or inside your plot.ly account where it is named 'Total Freq Plot'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sunchitsharma9/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def language_model(tokens,n,ps):\n",
    "# Build your language model\n",
    "# For any language model you build, print a sample of the top 10 and the bottom 10 frequently occuring N-grams.\n",
    "# For any language model you build, display plots of N-Gram vs Freq sorted by frequency (descending) and log-log plots of the same\n",
    "    \n",
    "    gm={}\n",
    "    \n",
    "    for i in range(0,len(tokens)):\n",
    "        temp=[]\n",
    "        flag=1\n",
    "        for j in range(i,n+i):\n",
    "            if(tokens[j]!=\"<EOS>\"):\n",
    "                temp.append(tokens[j])\n",
    "            else:\n",
    "                flag=0\n",
    "                break\n",
    "        if(flag==0):\n",
    "            i=j+1\n",
    "        else:\n",
    "            if tuple(temp) in gm.keys():\n",
    "                gm[tuple(temp)]+=1\n",
    "            else:\n",
    "                gm[tuple(temp)]=1\n",
    "    \n",
    "    sorted_gm = dict()\n",
    "    sorted_gm = sorted(gm.iteritems(),key=lambda (k,v): (v,k),reverse=True)\n",
    "    \n",
    "    if(ps):\n",
    "        print \"------Top ten N-Grams------\"\n",
    "\n",
    "        for i in range(0,9):\n",
    "            print(\"%s\\t\\t:\\t%d\" % (sorted_gm[i][0],sorted_gm[i][1]))\n",
    "\n",
    "        print \"------Bottom ten N-Grams------\"\n",
    "\n",
    "        for i in range(len(sorted_gm)-1,len(sorted_gm)-10,-1):\n",
    "            print(\"%s     :     %d\" % (sorted_gm[i][0],sorted_gm[i][1]))\n",
    "    \n",
    "    return sorted_gm\n",
    "    \n",
    "    \n",
    "##################################################################################################################\n",
    "    \n",
    "    \n",
    "def plotme(sorted_gm):\n",
    "    \n",
    "    xaxis=[]\n",
    "    \n",
    "    yaxis=[]\n",
    "    \n",
    "    for i in sorted_gm:\n",
    "        xaxis.append('_'.join(i[0]))\n",
    "        yaxis.append(i[1])\n",
    "                \n",
    "    \n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(\n",
    "        x = xaxis,\n",
    "        y = yaxis,\n",
    "        name = 'N-Gram Plot',\n",
    "        line = dict(\n",
    "            color = ('rgb(205, 12, 24)'),\n",
    "            width = 4)\n",
    "    )\n",
    "    \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'N-Gram Frequency Plot',\n",
    "                  xaxis = dict(title = 'N-Gram'),\n",
    "                  yaxis = dict(title = 'Frequency'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return fig\n",
    "    \n",
    "    \n",
    "#################################################################################################################\n",
    "\n",
    "\n",
    "def complete_ngram(ngram, n):\n",
    "# Given (N-1) gram, and the value 'N', print the possibilities that complete the n-gram\n",
    "# and plot them in decresing order of frequency\n",
    "    \n",
    "    next_word=[]\n",
    "    \n",
    "    for i in sorted_gm:\n",
    "        temp=[]\n",
    "        if list(i[0])[:-1]==ngram.split():\n",
    "            temp.append(i[0][-1])\n",
    "            temp.append(i[1])\n",
    "        if temp!=[]:\n",
    "            next_word.append(temp)\n",
    "    \n",
    "    \n",
    "    for i in range(0,n):\n",
    "        if(i<len(next_word)):\n",
    "            print(\"%s\\t:\\t%d\" % (next_word[i][0],next_word[i][1]))\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # NOW PLOTTING THEM\n",
    "            \n",
    "    xaxis=[]\n",
    "    yaxis=[]\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        if(i<len(next_word)):\n",
    "            xaxis.append(next_word[i][0])\n",
    "            yaxis.append(next_word[i][1])\n",
    "                \n",
    "    \n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(\n",
    "        x = xaxis,\n",
    "        y = yaxis,\n",
    "        name = 'N-Gram Plot',\n",
    "        line = dict(\n",
    "            color = ('rgb(205, 12, 24)'),\n",
    "            width = 4)\n",
    "    )\n",
    "    \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'Next Word Frequency Plot',\n",
    "                  xaxis = dict(title = 'Next Word'),\n",
    "                  yaxis = dict(title = 'Frequency'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "def laplace_smoothing(n_grams):\n",
    "    \n",
    "    numerator=0\n",
    "    denominator=0\n",
    "    \n",
    "    sorted_gm=language_model(tokens, len(n_grams.split()),False)\n",
    "    for i in sorted_gm:\n",
    "        if tuple(n_grams.split())==i[0]:\n",
    "            numerator=i[1]\n",
    "            break\n",
    "        \n",
    "    for i in sorted_gm:\n",
    "        if tuple(n_grams.split())[:-1]==i[0][:-1]:\n",
    "            denominator+=i[1]\n",
    "    \n",
    "    return ((numerator+1)*1.0)/(denominator+len(tokens))\n",
    "    \n",
    "\n",
    "\n",
    "# only 1 of the next 3 have to be implemented\n",
    "\n",
    "def witten_bell(n_grams):  # NOT DONE                       \n",
    "  # perform Witten-Bell smoothing\n",
    "    pass\n",
    "  \n",
    "def good_turing(n_grams):  \n",
    "  # perform Good Turing smoothing\n",
    "    gtt=tokenize(n_grams)\n",
    "    gtt_dict={}\n",
    "    count=0\n",
    "    sum=0\n",
    "    sorted_gm=language_model(tokens, len(gtt), False)\n",
    "    for i in sorted_gm:\n",
    "        if i[0] == tuple(gtt):\n",
    "            count+=i[1]\n",
    "        if i[1] not in gtt_dict.keys():\n",
    "            gtt_dict[i[1]]=1\n",
    "            sum+=1\n",
    "        else:\n",
    "            gtt_dict[i[1]]+=1\n",
    "            sum+=1\n",
    "    ans=0\n",
    "    if count == 0:                           # CASE OF 0\n",
    "        ans=gtt_dict[1]*1.0/sum\n",
    "    else:\n",
    "        nc=gtt_dict[count]                   # CASE WHEN C^n+1 exists\n",
    "        if count+1 in gtt_dict.keys():\n",
    "            nc1=gtt_dict[count+1]\n",
    "            ans=(count+1)*1.0*nc1/nc\n",
    "        else:                                # CASE WHEN C^n+1 does not exist\n",
    "            MAX= gtt_dict[min(gtt_dict.keys())]\n",
    "            ans=MAX*count**-2**1.0/sum\n",
    "    \n",
    "    return ans\n",
    "    \n",
    "    \n",
    "####################################################################################################################    \n",
    "\n",
    "\n",
    "def kneser_ney(n_grams):\n",
    "  # perform Kneser-Ney smoothing\n",
    "    pass\n",
    "\n",
    "\n",
    "# only 1 of the next 2 have to be implemented\n",
    "\n",
    "def backoff(n_grams):\n",
    "  # perform Backoff\n",
    "    one_gm = language_model(tokens,1,False)\n",
    "    two_gm = language_model(tokens,2,False)\n",
    "    three_gm = language_model(tokens,3,False)\n",
    "    \n",
    "    fd={}\n",
    "    \n",
    "    fd[1]=dict(one_gm)\n",
    "    fd[2]=dict(two_gm)\n",
    "    fd[3]=dict(three_gm)\n",
    "    \n",
    "    wt=tokenize(n_grams)\n",
    "    \n",
    "    final_backoff_score=0\n",
    "    \n",
    "    for i in range(0,len(wt)):\n",
    "        if len(wt[i:i+3])==3:\n",
    "            if tuple(wt[i:i+3]) in fd[3].keys():\n",
    "                final_backoff_score+=((fd[3][tuple(wt[i:i+3])])*1.0/fd[2][tuple(wt[i:i+2])])\n",
    "            elif tuple(wt[i:i+2]) in fd[2].keys():\n",
    "                final_backoff_score+=((fd[2][tuple(wt[i:i+2])])*1.0/(fd[1][tuple(wt[i:i+1])]+len(fd[2].keys())))\n",
    "            elif tuple(wt[i:i+1]) in fd[1].keys():\n",
    "                final_backoff_score+=((fd[1][tuple(wt[i:i+1])])*1.0/(0.0003+len(fd[1].keys())))\n",
    "            else:\n",
    "                final_backoff_score+=0.0003\n",
    "    \n",
    "    return final_backoff_score\n",
    "        \n",
    "    \n",
    "    \n",
    "    pass\n",
    "  \n",
    "def deleted_interpolation(n_grams):\n",
    "  # perform deleted Interpolation\n",
    "    pass\n",
    "\n",
    "\n",
    "text = \"i am a i am a i am the Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst. Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "tokens=tokenize(text) # TESTED\n",
    "sorted_gm=language_model(tokens, 3, True) \n",
    "\n",
    "\n",
    "\n",
    "print\n",
    "print \"LAPLACE : \"\n",
    "print laplace_smoothing(\"i am hello\")\n",
    "\n",
    "print\n",
    "print \"GOOD TURING : \"\n",
    "print good_turing(\"i am a\")\n",
    "\n",
    "print\n",
    "print \"BACKOFF : \"\n",
    "print backoff(\"i am a i am x y x the\")\n",
    "\n",
    "print\n",
    "print \"NEXT POSSIBLE WORDS WITH FREQUENCIES\"\n",
    "fig = complete_ngram(\"i am\",2) # FREQUENCY PLOT for next word\n",
    "py.plotly.iplot(fig, filename='Next_word_plot') \n",
    "\n",
    "fig = plotme(sorted_gm)  # FREQUENCY PLOT \n",
    "py.plotly.iplot(fig, filename='Total Freq Plot')\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjoF5Wlsaf_M"
   },
   "source": [
    "# Task 2: Unigrams and Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oehobp6dbXp7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUGGESTION\t:\tPROBABILITY\n",
      "------------------------------------\n",
      "his \t\t:\t0.333\n",
      "it \t\t:\t0.667\n",
      "By N-Gram model approach the word is correct by 100.00 Percent\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sunchitsharma9/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_ngram_freqs(ngrams):\n",
    "# Calculate unigram frequencies and plot them in the descending order of frequency\n",
    "# Example code for using plotly to plot frequencies\n",
    "    import plotly.plotly as py\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    # Add data\n",
    "    \n",
    "    unig = language_model(tokens,1,False)\n",
    "    \n",
    "    x_axis=[]\n",
    "    y_axis=[]\n",
    "    \n",
    "    for i in unig:\n",
    "        x_axis.append(i[0][0])\n",
    "        y_axis.append(i[1])\n",
    "        \n",
    "\n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(\n",
    "        x = x_axis,\n",
    "        y = y_axis,\n",
    "        name = 'Unigram Plot',\n",
    "        line = dict(\n",
    "            color = ('rgb(205, 12, 24)'),\n",
    "            width = 4)\n",
    "    )\n",
    "    \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'Unigram Plot',\n",
    "                  xaxis = dict(title = 'Tokens'),\n",
    "                  yaxis = dict(title = 'Frequency'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "def spell_checker(word, n_grams):\n",
    "# Given a word check if the spelling is correct using your Language model\n",
    "# Feel free to add more helper functions for this task\n",
    "    \n",
    "    neighbours=[]\n",
    "    alphabets = 'abcdefghijklmnopqrstuvwxyz\\'';\n",
    "    \n",
    "    # PART A : EDIT DISTANCE\n",
    "    if word in tokens:\n",
    "        print \"WORD IS CORRECT\"\n",
    "        print word # Why Correct, Correct words\n",
    "    \n",
    "    else:\n",
    "        # ADDITION\n",
    "        for i in alphabets:\n",
    "            for j in range(0,len(word)+1):\n",
    "                wl=list(word)\n",
    "                wl.insert(j,i)\n",
    "                neighbours.append(\"\".join(wl))\n",
    "        \n",
    "        # DELETION\n",
    "        for i in range(0,len(word)):\n",
    "            wl=list(word)\n",
    "            del wl[i]\n",
    "            neighbours.append(\"\".join(wl))\n",
    "            \n",
    "        # SWAP\n",
    "        for i in range(0,len(word)-1):\n",
    "            wl=list(word)\n",
    "            temp=wl[i]\n",
    "            wl[i]=wl[i+1]\n",
    "            wl[i+1]=temp\n",
    "            neighbours.append(\"\".join(wl))\n",
    "        \n",
    "        # REPLACE\n",
    "        for i in alphabets:\n",
    "            for j in range(0,len(word)):\n",
    "                wl=list(word)\n",
    "                wl[j]=i\n",
    "                neighbours.append(\"\".join(wl))\n",
    "                \n",
    "        valid=[]        \n",
    "    \n",
    "        for i in neighbours:\n",
    "            if i in tokens:\n",
    "                valid.append(i)\n",
    "        \n",
    "        neighbours=[] # FREE MEMORY\n",
    "        \n",
    "        model=language_model(tokens,1,False)\n",
    "        \n",
    "        match_count={}\n",
    "        sum=0\n",
    "        \n",
    "        for i in model:\n",
    "            if i[0][0] in valid:\n",
    "                match_count[i[0][0]]=i[1]\n",
    "                sum+=i[1]\n",
    "                \n",
    "                \n",
    "        print(\"SUGGESTION\\t:\\tPROBABILITY\")\n",
    "        print \"------------------------------------\"\n",
    "        for i in match_count:\n",
    "            print(\"%s \\t\\t:\\t%.3f\" % (i,match_count[i]*1.0/sum))\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "    # PART B : PROBABILITY OF CORRECTNESS\n",
    "    \n",
    "    # Generating n grams on characters\n",
    "    char_tokens={}\n",
    "    for i in tokens:\n",
    "        if i != \"<EOS>\":\n",
    "            for j in range(0,len(i)):\n",
    "                if i[j:n_grams] not in char_tokens.keys():\n",
    "                    if len(i[j:n_grams+j])==n_grams:\n",
    "                        char_tokens[i[j:n_grams+j]]=1\n",
    "                else:\n",
    "                    if len(i[j:n_grams+j])==n_grams:\n",
    "                        char_tokens[i[j:n_grams+j]]+=1\n",
    "\n",
    "    \n",
    "    # Breaking the word in grams\n",
    "    corr=0\n",
    "    tot=0\n",
    "    for j in range(0,len(i)-n_grams):\n",
    "        if len(word[j:n_grams+j])==n_grams:\n",
    "            if word[j:n_grams+j] in char_tokens.keys():\n",
    "                corr+=1\n",
    "            tot+=1\n",
    "        \n",
    "    print(\"By N-Gram model approach the word is correct by %.02f Percent\" % (corr*1.0*100/tot))\n",
    "\n",
    "text = \"i am a i am a i am the Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst. Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "tokens=tokenize(text) # TESTED\n",
    "spell_checker(\"hit\",2)\n",
    "\n",
    "fig = plot_ngram_freqs(1)\n",
    "py.plotly.iplot(fig, filename='Unigram_plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgPpfeyYgLUv"
   },
   "source": [
    "# Task 3 : Grammaticality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xX0RvOpLgYgR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Laplase gives : \n",
      "17.3124300112\n",
      "\n",
      "The Good Turing gives : \n",
      "7562.12551621\n",
      "\n",
      "The Backoff gives : \n",
      "5.66666666667\n"
     ]
    }
   ],
   "source": [
    "def score_grammaticality(sentence, language_model):\n",
    "  # Given a sentence, Build a model from the data which can give a score of grammaticality. \n",
    "  # More grammatical the sentence, better the score\n",
    "  # Feel free to add helper functions\n",
    "    x=1\n",
    "    c=0\n",
    "    wt=tokenize(sentence)\n",
    "    for i in range(0,len(wt)):\n",
    "        if len(wt[i:i+3])==3:\n",
    "            x= laplace_smoothing(\" \".join(wt[i:i+3]))+x\n",
    "            c+=1\n",
    "    \n",
    "    print(\"The Laplase gives : \")\n",
    "    print x*100/c\n",
    "    \n",
    "    c=0\n",
    "    x=1\n",
    "    for i in range(0,len(wt)):\n",
    "        if len(wt[i:i+3])==3:\n",
    "            x= good_turing(\" \".join(wt[i:i+3]))*x\n",
    "            c+=1\n",
    "    print\n",
    "    print(\"The Good Turing gives : \")\n",
    "    print 1*1.0/(x*c)\n",
    "    \n",
    "    x=backoff(sentence)\n",
    "    \n",
    "    print\n",
    "    print(\"The Backoff gives : \")\n",
    "    print x\n",
    "    \n",
    "    \n",
    "\n",
    "text = \"i am a i am a i am the Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst. Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "tokens=tokenize(text) # TESTED\n",
    "sorted_gm=language_model(tokens, 3, False) \n",
    "score_grammaticality(\"i am a i am a i am the\",sorted_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Error Correction Demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
