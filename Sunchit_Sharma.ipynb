{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZgGNXZEfywz"
   },
   "source": [
    "#Task 1: Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deLPHwbIX3-r"
   },
   "outputs": [],
   "source": [
    "# Download gutenberg dataset\n",
    "# This is the dataset on which all your models will be trained\n",
    "# https://drive.google.com/file/d/0B2Mzhc7popBga2RkcWZNcjlRTGM/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below task uses a regex to break a the grammer in words but the terminals do not get handled here. I have made a handler loop for breaking down sentences and add <EOS> ie End of Sentence in the end of every sentence as it woould be required in n-gram model generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08q0ospof2z9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, re\n",
    "import plotly as py\n",
    "py.tools.set_credentials_file(username='sunchitsharma8',api_key='zOo9Q8EKKKOHEfteuk0H')\n",
    "import plotly.graph_objs as go\n",
    "from itertools import tee, izip\n",
    "\n",
    "def is_number(s): # Helper Functions\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    text = text.lower(); # Case Folding\n",
    "    \n",
    "    split_text = re.split('; |,|\\*|\\n| |--|\\\"|_|, |\\r',text)\n",
    "    \n",
    "    # The issue is that we have not handled \".\" and Dr. and such types are not handled.\n",
    "    \n",
    "    Dot_Handler = [\"ie.\",\"i.e.\",\"inc.\",\"i.o.u.\",\"m.d.\",\"n.b.\",\"p.o.\",\"u.k.\",\"u.s.\",\"u.s.a.\",\"p.s.\",\".c\",\"mr.\",\"mrs.\",\"ms.\",\".com\",\"dr.\",\".sh\",\".java\",\"st.\",\"jr.\",\"ph.d.\"]\n",
    "    \n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    \n",
    "    # Web_Extentions = [\".com\",\".in\",\".org\",\".edu\",\".net\",\".gov\",\".info\",\".biz\"] Automatically Handled\n",
    "    \n",
    "    counter = -1;\n",
    "    \n",
    "    split_final=[]\n",
    "    temp=[]\n",
    "    \n",
    "    for i in split_text:\n",
    "        counter+=1\n",
    "        if i:\n",
    "            if i[-1] in punctuations:\n",
    "                if i not in Dot_Handler:\n",
    "                    tempvar = re.sub(r'[^\\w\\s]','',i)\n",
    "                    temp.append(tempvar)\n",
    "                    temp = list(filter(None, temp))\n",
    "                    split_final.append(temp)\n",
    "                    temp=[]\n",
    "                else:\n",
    "                    temp.append(i)\n",
    "            else:\n",
    "                temp.append(i)\n",
    "                \n",
    "    if temp !=[]:\n",
    "        split_final.append(temp)\n",
    "    \n",
    "                \n",
    "    return split_final\n",
    "    \n",
    "def read_files(files):\n",
    "    text=\"\"\n",
    "    for name in files:\n",
    "        f = open(name,\"r\")\n",
    "        text=text+\"\\r\\n\"+f.read()\n",
    "    return text\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "path = './td/*.txt'\n",
    "files = glob.glob(path)\n",
    "text=read_files(files)\n",
    "#text = \"i am a i am a, Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst! Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "tokens=tokenize(text)\n",
    "print \"-----------------------------------------------------TOKENS-----------------------------------------------------\"\n",
    "print tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7gwBEe5bgAbn"
   },
   "source": [
    "#Language Model and Smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Th9ogrogKTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Top ten N-Grams------\n",
      "('the', 'united', 'states')\t\t:\t82\n",
      "('of', 'the', 'united')\t\t:\t56\n",
      "('i', 'do', 'not')\t\t:\t55\n",
      "('the', 'people', 'of')\t\t:\t51\n",
      "('there', 'is', 'no')\t\t:\t41\n",
      "('of', 'the', 'people')\t\t:\t41\n",
      "('it', 'is', 'a')\t\t:\t40\n",
      "('that', 'it', 'is')\t\t:\t38\n",
      "('as', 'well', 'as')\t\t:\t37\n",
      "------Bottom ten N-Grams------\n",
      "('$400', '000', '000')     :     1\n",
      "(\"'87\", 'was', 'valid')     :     1\n",
      "(\"'a\", 'house', 'divided')     :     1\n",
      "(\"'blondin\", 'stand', 'up')     :     1\n",
      "(\"'s\", 'approval', 'touched')     :     1\n",
      "(\"'take\", 'out', 'the')     :     1\n",
      "(\"'the\", 'complete', 'works')     :     1\n",
      "(\"'the\", 'people', 'of')     :     1\n",
      "(\"'there's\", 'one', 'of')     :     1\n",
      "[(('of', 'the', 'united'), 56), (('i', 'do', 'not'), 55), (('the', 'people', 'of'), 51), (('there', 'is', 'no'), 41), (('of', 'the', 'people'), 41), (('it', 'is', 'a'), 40), (('that', 'it', 'is'), 38), (('as', 'well', 'as'), 37), (('in', 'favour', 'of'), 34)]\n"
     ]
    }
   ],
   "source": [
    "def window(iterable, size):\n",
    "    iters = tee(iterable, size)\n",
    "    for i in xrange(1, size):\n",
    "        for each in iters[i:]:\n",
    "            next(each, None)\n",
    "    return izip(*iters)\n",
    "\n",
    "def language_model(tokens,n,ps):\n",
    "# Build your language model\n",
    "# For any language model you build, print a sample of the top 10 and the bottom 10 frequently occuring N-grams.\n",
    "# For any language model you build, display plots of N-Gram vs Freq sorted by frequency (descending) and log-log plots of the same\n",
    "    \n",
    "    from itertools import tee, izip\n",
    "    \n",
    "    gm={}\n",
    "\n",
    "    for i in tokens:\n",
    "        for each in window(i, n):\n",
    "            temp=list(each)\n",
    "            if tuple(temp) in gm.keys():\n",
    "                gm[tuple(list(each))]+=1\n",
    "            else:\n",
    "                gm[tuple(list(each))]=1\n",
    "            \n",
    "\n",
    "    \n",
    "    sorted_gm = dict()\n",
    "    sorted_gm = sorted(gm.iteritems(),key=lambda (k,v): (v,k),reverse=True)\n",
    "    \n",
    "    if(ps):\n",
    "        print \"------Top ten N-Grams------\"\n",
    "\n",
    "        for i in range(0,9):\n",
    "            print(\"%s\\t\\t:\\t%d\" % (sorted_gm[i][0],sorted_gm[i][1]))\n",
    "\n",
    "        print \"------Bottom ten N-Grams------\"\n",
    "\n",
    "        for i in range(len(sorted_gm)-1,len(sorted_gm)-10,-1):\n",
    "            print(\"%s     :     %d\" % (sorted_gm[i][0],sorted_gm[i][1]))\n",
    "    \n",
    "    return sorted_gm\n",
    "\n",
    "\n",
    "### TEST CODE ##\n",
    "\n",
    "sorted_gm=language_model(tokens, 3, True) \n",
    "print sorted_gm[1:10]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/plotly/plotly/plotly.py:233: UserWarning:\n",
      "\n",
      "Woah there! Look at all those points! Due to browser limitations, the Plotly SVG drawing functions have a hard time graphing more than 500k data points for line charts, or 40k points for other types of charts. Here are some suggestions:\n",
      "(1) Use the `plotly.graph_objs.Scattergl` trace object to generate a WebGl graph.\n",
      "(2) Trying using the image API to return an image instead of a graph URL\n",
      "(3) Use matplotlib\n",
      "(4) See if you can create your visualization with fewer data points\n",
      "\n",
      "If the visualization you're using aggregates points (e.g., box plot, histogram, etc.) you can disregard this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The draw time for this plot will be slow for all clients.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/plotly/api/v1/clientresp.py:40: UserWarning:\n",
      "\n",
      "Estimated Draw Time Too Long\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sunchitsharma8/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plotme(sorted_gm):\n",
    "    \n",
    "    xaxis=[]\n",
    "    \n",
    "    yaxis=[]\n",
    "    \n",
    "    for i in sorted_gm:\n",
    "        xaxis.append('_'.join(i[0]))\n",
    "        yaxis.append(i[1])\n",
    "                \n",
    "    \n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(\n",
    "        x = xaxis,\n",
    "        y = yaxis,\n",
    "        name = 'N-Gram Plot',\n",
    "        line = dict(\n",
    "            color = ('rgb(205, 12, 24)'),\n",
    "            width = 4)\n",
    "    )\n",
    "    \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'N-Gram Frequency Plot',\n",
    "                  xaxis = dict(title = 'N-Gram'),\n",
    "                  yaxis = dict(title = 'Frequency'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "##### TEST CODE #####\n",
    "\n",
    "fig = plotme(sorted_gm)  # FREQUENCY PLOT \n",
    "py.plotly.iplot(fig, filename='Total Freq Plot')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEXT POSSIBLE WORDS WITH FREQUENCIES\n",
      "not\t:\t15\n",
      "in\t:\t13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sunchitsharma8/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete_ngram(ngram, n):\n",
    "# Given (N-1) gram, and the value 'N', print the possibilities that complete the n-gram\n",
    "# and plot them in decresing order of frequency\n",
    "    \n",
    "    next_word=[]\n",
    "    \n",
    "    for i in sorted_gm:\n",
    "        temp=[]\n",
    "        if list(i[0])[:-1]==ngram.split():\n",
    "            temp.append(i[0][-1])\n",
    "            temp.append(i[1])\n",
    "        if temp!=[]:\n",
    "            next_word.append(temp)\n",
    "    \n",
    "    \n",
    "    for i in range(0,n):\n",
    "        if(i<len(next_word)):\n",
    "            print(\"%s\\t:\\t%d\" % (next_word[i][0],next_word[i][1]))\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # NOW PLOTTING THEM\n",
    "            \n",
    "    xaxis=[]\n",
    "    yaxis=[]\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        if(i<len(next_word)):\n",
    "            xaxis.append(next_word[i][0])\n",
    "            yaxis.append(next_word[i][1])\n",
    "                \n",
    "    \n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(\n",
    "        x = xaxis,\n",
    "        y = yaxis,\n",
    "        name = 'N-Gram Plot',\n",
    "        line = dict(\n",
    "            color = ('rgb(205, 12, 24)'),\n",
    "            width = 4)\n",
    "    )\n",
    "    \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'Next Word Frequency Plot',\n",
    "                  xaxis = dict(title = 'Next Word'),\n",
    "                  yaxis = dict(title = 'Frequency'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "#### TEST CODE ####\n",
    "\n",
    "print \"NEXT POSSIBLE WORDS WITH FREQUENCIES\"\n",
    "fig = complete_ngram(\"i am\",2) # FREQUENCY PLOT for next word\n",
    "py.plotly.iplot(fig, filename='Next_word_plot') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAPLACE : \n",
      "0.000230255583698\n"
     ]
    }
   ],
   "source": [
    "def laplace_smoothing(n_grams):\n",
    "    \n",
    "    numerator=0\n",
    "    denominator=0\n",
    "    \n",
    "    sorted_gm=language_model(tokens, len(n_grams.split()),False)\n",
    "    for i in sorted_gm:\n",
    "        if tuple(n_grams.split())==i[0]:\n",
    "            numerator=i[1]\n",
    "            break\n",
    "        \n",
    "    for i in sorted_gm:\n",
    "        if tuple(n_grams.split())[:-1]==i[0][:-1]:\n",
    "            denominator+=i[1]\n",
    "    \n",
    "    return ((numerator+1)*1.0)/(denominator+len(tokens))\n",
    "    \n",
    "    \n",
    "##### TEST CODE #####\n",
    "\n",
    "print \"LAPLACE : \"\n",
    "print laplace_smoothing(\"i am hello\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 1 of the next 3 have to be implemented\n",
    "\n",
    "def witten_bell(n_grams):  # NOT DONE                       \n",
    "  # perform Witten-Bell smoothing\n",
    "    pass\n",
    "  \n",
    "def good_turing(n_grams):  \n",
    "  # perform Good Turing smoothing\n",
    "    gtt=tokenize(n_grams)\n",
    "    print gtt\n",
    "    gtt_dict={}\n",
    "    count=0\n",
    "    sum=0\n",
    "    sorted_gm=language_model(tokens, len(gtt), False)\n",
    "    for i in sorted_gm:\n",
    "        if i[0] == tuple(gtt):\n",
    "            count+=i[1]\n",
    "        if i[1] not in gtt_dict.keys():\n",
    "            gtt_dict[i[1]]=1\n",
    "            sum+=1\n",
    "        else:\n",
    "            gtt_dict[i[1]]+=1\n",
    "            sum+=1\n",
    "    ans=0\n",
    "    if count == 0:                           # CASE OF 0\n",
    "        print gtt_dict.keys()\n",
    "        ans=gtt_dict[min(gtt_dict.keys())]*1.0/sum\n",
    "    else:\n",
    "        nc=gtt_dict[count]                   # CASE WHEN C^n+1 exists\n",
    "        if count+1 in gtt_dict.keys():\n",
    "            nc1=gtt_dict[count+1]\n",
    "            ans=(count+1)*1.0*nc1/nc\n",
    "        else:                                # CASE WHEN C^n+1 does not exist\n",
    "            MAX= gtt_dict[min(gtt_dict.keys())]\n",
    "            ans=MAX*count**-2**1.0/sum\n",
    "    \n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "def kneser_ney(n_grams):\n",
    "  # perform Kneser-Ney smoothing\n",
    "    pass\n",
    "\n",
    "\n",
    "#### TEST CODE ####\n",
    "\n",
    "print \"GOOD TURING : \"\n",
    "print good_turing(\"i am a boy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 1 of the next 2 have to be implemented\n",
    "\n",
    "def backoff(n_grams):\n",
    "  # perform Backoff\n",
    "    one_gm = language_model(tokens,1,False)\n",
    "    two_gm = language_model(tokens,2,False)\n",
    "    three_gm = language_model(tokens,3,False)\n",
    "    \n",
    "    fd={}\n",
    "    \n",
    "    fd[1]=dict(one_gm)\n",
    "    fd[2]=dict(two_gm)\n",
    "    fd[3]=dict(three_gm)\n",
    "    \n",
    "    wt=tokenize(n_grams)\n",
    "    \n",
    "    final_backoff_score=0\n",
    "    \n",
    "    for i in range(0,len(wt)):\n",
    "        if len(wt[i:i+3])==3:\n",
    "            if tuple(wt[i:i+3]) in fd[3].keys():\n",
    "                final_backoff_score+=((fd[3][tuple(wt[i:i+3])])*1.0/fd[2][tuple(wt[i:i+2])])\n",
    "            elif tuple(wt[i:i+2]) in fd[2].keys():\n",
    "                final_backoff_score+=((fd[2][tuple(wt[i:i+2])])*1.0/(fd[1][tuple(wt[i:i+1])]+len(fd[2].keys())))\n",
    "            elif tuple(wt[i:i+1]) in fd[1].keys():\n",
    "                final_backoff_score+=((fd[1][tuple(wt[i:i+1])])*1.0/(0.0003+len(fd[1].keys())))\n",
    "            else:\n",
    "                final_backoff_score+=0.0003\n",
    "    \n",
    "    return final_backoff_score\n",
    "        \n",
    "    \n",
    "    \n",
    "    pass\n",
    "  \n",
    "def deleted_interpolation(n_grams):\n",
    "  # perform deleted Interpolation\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#### TEST CODE ####\n",
    "\n",
    "print \"BACKOFF : \"\n",
    "print backoff(\"i am a i am x y x the\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IjoF5Wlsaf_M"
   },
   "source": [
    "# Task 2: Unigrams and Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oehobp6dbXp7"
   },
   "outputs": [],
   "source": [
    "def plot_ngram_freqs(ngrams):\n",
    "# Calculate unigram frequencies and plot them in the descending order of frequency\n",
    "# Example code for using plotly to plot frequencies\n",
    "    import plotly.plotly as py\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    # Add data\n",
    "    \n",
    "    unig = language_model(tokens,1,False)\n",
    "    \n",
    "    x_axis=[]\n",
    "    y_axis=[]\n",
    "    \n",
    "    for i in unig:\n",
    "        x_axis.append(i[0][0])\n",
    "        y_axis.append(i[1])\n",
    "        \n",
    "\n",
    "    # Create and style traces\n",
    "    trace0 = go.Scatter(\n",
    "        x = x_axis,\n",
    "        y = y_axis,\n",
    "        name = 'Unigram Plot',\n",
    "        line = dict(\n",
    "            color = ('rgb(205, 12, 24)'),\n",
    "            width = 4)\n",
    "    )\n",
    "    \n",
    "    data = [trace0]\n",
    "\n",
    "    # Edit the layout\n",
    "    layout = dict(title = 'Unigram Plot',\n",
    "                  xaxis = dict(title = 'Tokens'),\n",
    "                  yaxis = dict(title = 'Frequency'),\n",
    "                  )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    return fig\n",
    "\n",
    "def spell_checker(word, n_grams):\n",
    "# Given a word check if the spelling is correct using your Language model\n",
    "# Feel free to add more helper functions for this task\n",
    "    \n",
    "    neighbours=[]\n",
    "    alphabets = 'abcdefghijklmnopqrstuvwxyz\\'';\n",
    "    \n",
    "    # PART A : EDIT DISTANCE\n",
    "    if word in tokens:\n",
    "        print \"WORD IS CORRECT\"\n",
    "        print word # Why Correct, Correct words\n",
    "    \n",
    "    else:\n",
    "        # ADDITION\n",
    "        for i in alphabets:\n",
    "            for j in range(0,len(word)+1):\n",
    "                wl=list(word)\n",
    "                wl.insert(j,i)\n",
    "                neighbours.append(\"\".join(wl))\n",
    "        \n",
    "        # DELETION\n",
    "        for i in range(0,len(word)):\n",
    "            wl=list(word)\n",
    "            del wl[i]\n",
    "            neighbours.append(\"\".join(wl))\n",
    "            \n",
    "        # SWAP\n",
    "        for i in range(0,len(word)-1):\n",
    "            wl=list(word)\n",
    "            temp=wl[i]\n",
    "            wl[i]=wl[i+1]\n",
    "            wl[i+1]=temp\n",
    "            neighbours.append(\"\".join(wl))\n",
    "        \n",
    "        # REPLACE\n",
    "        for i in alphabets:\n",
    "            for j in range(0,len(word)):\n",
    "                wl=list(word)\n",
    "                wl[j]=i\n",
    "                neighbours.append(\"\".join(wl))\n",
    "                \n",
    "        valid=[]        \n",
    "    \n",
    "        for i in neighbours:\n",
    "            if i in tokens:\n",
    "                valid.append(i)\n",
    "        \n",
    "        neighbours=[] # FREE MEMORY\n",
    "        \n",
    "        model=language_model(tokens,1,False)\n",
    "        \n",
    "        match_count={}\n",
    "        sum=0\n",
    "        \n",
    "        for i in model:\n",
    "            if i[0][0] in valid:\n",
    "                match_count[i[0][0]]=i[1]\n",
    "                sum+=i[1]\n",
    "                \n",
    "                \n",
    "        print(\"SUGGESTION\\t:\\tPROBABILITY\")\n",
    "        print \"------------------------------------\"\n",
    "        for i in match_count:\n",
    "            print(\"%s \\t\\t:\\t%.3f\" % (i,match_count[i]*1.0/sum))\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "    # PART B : PROBABILITY OF CORRECTNESS\n",
    "    \n",
    "    # Generating n grams on characters\n",
    "    char_tokens={}\n",
    "    for i in tokens:\n",
    "            for k in range(0,len(i)):\n",
    "                    for j in range(0,len(i[k])):\n",
    "                        if i[j:n_grams] not in char_tokens.keys():\n",
    "                            if len(i[j:n_grams+j])==n_grams:\n",
    "                                char_tokens[i[j:n_grams+j]]=1\n",
    "                        else:\n",
    "                            if len(i[j:n_grams+j])==n_grams:\n",
    "                                char_tokens[i[j:n_grams+j]]+=1\n",
    "\n",
    "    \n",
    "    # Breaking the word in grams\n",
    "    corr=0\n",
    "    tot=0\n",
    "    for j in range(0,len(i)-n_grams):\n",
    "        if len(word[j:n_grams+j])==n_grams:\n",
    "            if word[j:n_grams+j] in char_tokens.keys():\n",
    "                corr+=1\n",
    "            tot+=1\n",
    "        \n",
    "    print(\"By N-Gram model approach the word is correct by %.02f Percent\" % (corr*1.0*100/tot))\n",
    "\n",
    "    \n",
    "def read_files(files):\n",
    "    text=\"\"\n",
    "    for name in files:\n",
    "        print name\n",
    "        f = open(name,\"r\")\n",
    "        text=text+\"\\r\\n\"+f.read()\n",
    "    return text\n",
    "\n",
    "\n",
    " \n",
    "#### TEST CODE ####\n",
    "\n",
    "\n",
    "#text = \"i am a i am a i am the Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst. Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "#tokens=tokenize(text) # TESTED\n",
    "\n",
    "\n",
    "#### ACTUAL TEST ####\n",
    "\n",
    "spell_checker(\"hit\",2)\n",
    "\n",
    "fig = plot_ngram_freqs(1)\n",
    "py.plotly.iplot(fig, filename='Unigram_plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgPpfeyYgLUv"
   },
   "source": [
    "# Task 3 : Grammaticality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xX0RvOpLgYgR"
   },
   "outputs": [],
   "source": [
    "def score_grammaticality(sentence, language_model):\n",
    "  # Given a sentence, Build a model from the data which can give a score of grammaticality. \n",
    "  # More grammatical the sentence, better the score\n",
    "  # Feel free to add helper functions\n",
    "    x=1\n",
    "    c=0\n",
    "    wt=tokenize(sentence)\n",
    "    for i in range(0,len(wt)):\n",
    "        if len(wt[i:i+3])==3:\n",
    "            x= laplace_smoothing(\" \".join(wt[i:i+3]))+x\n",
    "            c+=1\n",
    "    \n",
    "    print(\"The Laplase gives : \")\n",
    "    print x*100/c\n",
    "    \n",
    "    c=0\n",
    "    x=1\n",
    "    for i in range(0,len(wt)):\n",
    "        if len(wt[i:i+3])==3:\n",
    "            x= good_turing(\" \".join(wt[i:i+3]))*x\n",
    "            c+=1\n",
    "    print\n",
    "    print(\"The Good Turing gives : \")\n",
    "    print 1*1.0/(x*c)\n",
    "    \n",
    "    x=backoff(sentence)\n",
    "    \n",
    "    print\n",
    "    print(\"The Backoff gives : \")\n",
    "    print x\n",
    "    \n",
    "    \n",
    "def read_files(files):\n",
    "    text=\"\"\n",
    "    for name in files:\n",
    "        print name\n",
    "        f = open(name,\"r\")\n",
    "        text=text+\"\\r\\n\"+f.read()\n",
    "    return text\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "path = './td/*.txt'\n",
    "files = glob.glob(path)\n",
    "text=read_files(files)\n",
    "#text = \"i am a i am a i am the Mr. John Johnson Jr. was born in the U.S.A but earned his Ph.D. in Israel before joining Nike Inc. as an engineer. He also worked at craigslist.org as a business analyst. Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of 0.9 it isn't don's in Israel ok.\"\n",
    "tokens=tokenize(text) # TESTED\n",
    "sorted_gm=language_model(tokens, 3, False) \n",
    "score_grammaticality(\"did not invalidate the conclusion\",sorted_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Error Correction Demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
